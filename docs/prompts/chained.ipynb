{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "407ca0c3-ddd5-478e-9c7a-c958a9480b77",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Chained Prompt Template\n",
    "\n",
    "Sometimes, you may want to append prompt templates together. For example:\n",
    "\n",
    "- When you want to reuse the same chunk of templating in multiple places\n",
    "- When you are running a chain that depends on prior context\n",
    "\n",
    "In that case, you can use the `ChainedPromptTemplate` to chain these templates together. (Note the possibility of intermingling `PromptTemplate`'s with plain strings.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "496371c6-3653-4749-a9ed-1a14509568ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have access to Search.\n",
      "\n",
      "Your objective is to answer the question: how high is Everest?\n",
      "\n",
      "What is your next action?\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain_contrib.prompts import ChainedPromptTemplate\n",
    "\n",
    "template = ChainedPromptTemplate([\n",
    "    PromptTemplate.from_template(\"You have access to {tools}.\"),\n",
    "    \"Your objective is to answer the question: {question}?\",\n",
    "    \"What is your next action?\",\n",
    "], joiner=\"\\n\\n\")\n",
    "print(template.format(tools=\"Search\", question=\"how high is Everest\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d7e8e2-2ff6-4da6-8e6c-a30d09b0e91c",
   "metadata": {},
   "source": [
    "## Chaining chat templates\n",
    "\n",
    "You can also chain arbitrary chat prompt templates or message prompt templates together. Plain strings are intepreted as Human messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a5c3efd-7c1f-40d2-bee9-b3cf65f50c49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You have access to Search.', additional_kwargs={}),\n",
       " SystemMessage(content='Your objective is to answer human questions.', additional_kwargs={}),\n",
       " HumanMessage(content='Tell me: how high is Everest?', additional_kwargs={})]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate, SystemMessagePromptTemplate\n",
    "\n",
    "template = ChainedPromptTemplate([\n",
    "    SystemMessagePromptTemplate.from_template(\"You have access to {tools}.\"),\n",
    "    ChatPromptTemplate.from_messages([\n",
    "        SystemMessagePromptTemplate.from_template(\"Your objective is to answer human questions.\"),\n",
    "    ]),\n",
    "    \"Tell me: {question}?\",\n",
    "])\n",
    "template.format_prompt(tools=\"Search\", question=\"how high is Everest\").to_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684940d8-cf03-48ff-924d-8bb2cad26d55",
   "metadata": {},
   "source": [
    "## Chained Prompt Values\n",
    "\n",
    "If you already have `PromptValue`'s instead of `PromptTemplate`'s and just want to chain these values up, you can create a `ChainedPromptValue`. The values can be a mix of `StringPromptValue` and `ChatPromptValue`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fd67007-86b8-4f8a-8e05-32f477b64d37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You have access to Search.\n",
      "AI: What can I help with?\n",
      "What is langchain-contrib?\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts.base import StringPromptValue\n",
    "from langchain.prompts.chat import ChatPromptValue\n",
    "from langchain.schema import SystemMessage, AIMessage\n",
    "from langchain_contrib.prompts import ChainedPromptValue\n",
    "\n",
    "value = ChainedPromptValue(\n",
    "    joiner=\"\\n\",\n",
    "    subvalues=[\n",
    "        ChatPromptValue(\n",
    "            messages=[\n",
    "                SystemMessage(content=\"You have access to Search.\"),\n",
    "                AIMessage(content=\"What can I help with?\"),\n",
    "            ]\n",
    "        ),\n",
    "        StringPromptValue(text=\"What is langchain-contrib?\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(value.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1153bdac-9279-4983-9590-f28a5bb835cc",
   "metadata": {},
   "source": [
    "Chat message serialization is also supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19dc2416-6d0e-485c-8b8d-195df228afa8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You have access to Search.', additional_kwargs={}),\n",
       " AIMessage(content='What can I help with?', additional_kwargs={}),\n",
       " HumanMessage(content='What is langchain-contrib?', additional_kwargs={})]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value.to_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5247b0b1-d3f0-4b82-9d5e-bdde292639a1",
   "metadata": {},
   "source": [
    "## Prefixing prompt templates\n",
    "\n",
    "If you specifically want to just prepend a prefix to the current prompt template, as opposed to the much more general capabilities that `ChainedPromptTemplate` offers, then head on to the next page to learn about using `PrefixedTemplate` to do just that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
