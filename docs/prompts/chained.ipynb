{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "407ca0c3-ddd5-478e-9c7a-c958a9480b77",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Chained Prompt Template\n",
    "\n",
    "Sometimes, you may want to append prompt templates together. For example:\n",
    "\n",
    "- When you want to reuse the same chunk of templating in multiple places\n",
    "- When you are running a chain that depends on prior context\n",
    "\n",
    "In that case, you can use the `ChainedPromptTemplate` to chain these templates together. (Note the possibility of intermingling `PromptTemplate`'s with plain strings.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "496371c6-3653-4749-a9ed-1a14509568ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have access to Search.\n",
      "\n",
      "Your objective is to answer the question: how high is Everest?\n",
      "\n",
      "What is your next action?\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain_contrib.chains import ChainedPromptTemplate\n",
    "\n",
    "template = ChainedPromptTemplate([\n",
    "    PromptTemplate.from_template(\"You have access to {tools}.\"),\n",
    "    \"Your objective is to answer the question: {question}?\",\n",
    "    \"What is your next action?\",\n",
    "], joiner=\"\\n\\n\")\n",
    "print(template.format(tools=\"Search\", question=\"how high is Everest\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d7e8e2-2ff6-4da6-8e6c-a30d09b0e91c",
   "metadata": {},
   "source": [
    "## Chaining chat templates\n",
    "\n",
    "You can also chain arbitrary chat prompt templates or message prompt templates together. Plain strings are intepreted as Human messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a5c3efd-7c1f-40d2-bee9-b3cf65f50c49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You have access to Search.', additional_kwargs={}), SystemMessage(content='Your objective is to answer human questions.', additional_kwargs={}), HumanMessage(content='Tell me: how high is Everest?', additional_kwargs={})])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate, SystemMessagePromptTemplate\n",
    "\n",
    "template = ChainedPromptTemplate([\n",
    "    SystemMessagePromptTemplate.from_template(\"You have access to {tools}.\"),\n",
    "    ChatPromptTemplate.from_messages([\n",
    "        SystemMessagePromptTemplate.from_template(\"Your objective is to answer human questions.\"),\n",
    "    ]),\n",
    "    \"Tell me: {question}?\",\n",
    "])\n",
    "template.format_prompt(tools=\"Search\", question=\"how high is Everest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5247b0b1-d3f0-4b82-9d5e-bdde292639a1",
   "metadata": {},
   "source": [
    "## Prefixing prompt templates\n",
    "\n",
    "If you specifically want to just prepend a prefix to the current prompt template, as opposed to the much more general capabilities that `ChainedPromptTemplate` offers, then head on to the next session to learn about using `PrefixedTemplate` to do just that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
