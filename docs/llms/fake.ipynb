{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "599a5dc6-2f3b-40dd-8d98-ca686a52a200",
   "metadata": {},
   "source": [
    "# Fake LLM\n",
    "\n",
    "This fake LLM can be useful for mocking LLM calls during testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9214ecf6-39ec-4582-9403-7c595056beb7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'foo'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_contrib.llms import FakeLLM\n",
    "\n",
    "llm = FakeLLM()\n",
    "llm(\"Dummy prompt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb63a161-16a1-4f63-9bba-3d4455cf2a59",
   "metadata": {},
   "source": [
    "## Custom responses\n",
    "\n",
    "You can specify custom responses for exact prompt matches by specifying `mapped_responses`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23c7e012-b350-48d0-856a-d7c82a65400c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Custom response'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = FakeLLM(mapped_responses={\"Exact prompt\": \"Custom response\"})\n",
    "llm(\"Exact prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72eb36d6-7b27-47e0-9fc2-ff65ecf5bae9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'foo'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"A different prompt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e2ddb3-db3d-4cf0-b5a4-8a14cb9b45e2",
   "metadata": {},
   "source": [
    "In practice, prompts can get really complicated really fast. As such, you can also specify responses to simply be returned in order by specifying `sequenced_responses` instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8241f604-72f4-4780-ab4c-90759db20fd8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = FakeLLM(sequenced_responses=[\"One\", \"Two\", \"Three\"])\n",
    "llm(\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a42aff0a-6099-4e08-b90a-8bace0ce14e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Two'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bbb6d9a-157e-4765-9c0f-962f92d99e54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Three'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49ae2d8e-aef0-4848-bd43-40ef42da4fc8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'foo'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a11137-48fb-4590-8acc-4dcde10cff79",
   "metadata": {},
   "source": [
    "## Enforcing stops\n",
    "\n",
    "If you want to make sure your stop logic is working properly, you can also test for that by setting `check_stops` to True. This will now raise if you forgot to call the LLM with a stop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d5a47f5-d2ee-4e06-8591-30d0fff84b21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop has not been set\n"
     ]
    }
   ],
   "source": [
    "llm = FakeLLM(check_stops=True, mapped_responses={\"Can't stop\": \"Won't stop.\"})\n",
    "try:\n",
    "    llm(\"Can't stop\")\n",
    "except AssertionError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb93843-c0c6-400c-8490-49489c7f527b",
   "metadata": {},
   "source": [
    "This will also raise if you call the LLM with the wrong stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eccbdadd-f6d0-45d1-91af-0c7c50c82ecc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output 'Won't stop.' does not end in ['!']\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    llm(\"Can't stop\", stop=[\"!\"])\n",
    "except AssertionError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8612ef4-7247-40fc-a99a-33f9cb972a44",
   "metadata": {},
   "source": [
    "You will need to call the LLM with the right stop for the right response to be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1493c2a-ca92-4d41-82d6-15bae4ba53cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Won't stop\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"Can't stop\", stop=[\".\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
