interactions:
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - 127.0.0.1:8935
      user-agent:
      - python-httpx/0.23.3
    method: GET
    uri: http://127.0.0.1:8935/ping
  response:
    content: ought-ice says pong
    headers:
      cache-control:
      - no-transform
      content-length:
      - '19'
      content-type:
      - text/plain; charset=utf-8
      date:
      - Wed, 07 Jun 2023 01:55:38 GMT
      server:
      - uvicorn
    http_version: HTTP/1.1
    status_code: 200
- request:
    body: '{"prompt": ["Answer the following questions as best you can. You have access
      to the following tools:\n\nTerminal: Executes commands in a terminal. Input
      should be valid commands, and the output will be any output from running that
      command.\n\nUse the following format:\n\nQuestion: the input question you must
      answer\nThought: you should always think about what to do\nAction: the action
      to take, should be one of [Terminal]\nAction Input: the input to the action\nObservation:
      the result of the action\n... (this Thought/Action/Action Input/Observation
      can repeat N times)\nThought: I now know the final answer\nFinal Answer: the
      final answer to the original input question\n\nBegin!\n\nQuestion: List the
      folders in the current directory. Enter into one of them. List folders again.\nThought:"],
      "model": "text-davinci-003", "temperature": 0.0, "max_tokens": 256, "top_p":
      1, "frequency_penalty": 0, "presence_penalty": 0, "n": 1, "logit_bias": {},
      "stop": ["\nObservation:"]}'
    headers:
      Accept:
      - '*/*'
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      Content-Length:
      - '978'
      Content-Type:
      - application/json
      User-Agent:
      - OpenAI/v1 PythonBindings/0.27.2
    method: POST
    uri: https://api.openai.com/v1/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA0TQwWoCMRCA4XufIsw5ll2lW81NehKKrVDsoS0Sk1Fjk5klmRWp+O5lxdbrNz/D
        MCcIHgy41MbB44vb+vf5eF83zdo+lzBfPPwclsunxWtOoIHXe3QCBgSPsnKc2ogSmECDy2gFPZi6
        GTd1NZyMJhoSe4zXfODtIZALg6oa9f2Og8MC5uN0GYMBNVOE6JWw6goq2aESzCmQjb3FUOSCG44e
        c1GWvEISzCqQsGJCxZu+SPefNHX9YUa9XTf8iZpR24lRsYCGQB6PYCoNkbdt5nUBQ12MGjaBQtmt
        MtrCBAaKcAvnLw1dsVsEc4I2c2plJfyNVMDU40rD7SP/Pmw0CIuNN6ma8/nuFwAA//8DAPlStEN3
        AQAA
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 7d35462a7d4b274b-ADL
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Wed, 07 Jun 2023 01:55:41 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - text-davinci-003
      openai-organization:
      - user-dpc5ftw8bvmpxblb49hwviq5
      openai-processing-ms:
      - '1821'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '3000'
      x-ratelimit-limit-tokens:
      - '250000'
      x-ratelimit-remaining-requests:
      - '2999'
      x-ratelimit-remaining-tokens:
      - '249744'
      x-ratelimit-reset-requests:
      - 20ms
      x-ratelimit-reset-tokens:
      - 61ms
      x-request-id:
      - b37ea6eaf27ee075b3573b0066f0f0a9
    status:
      code: 200
      message: OK
version: 1
